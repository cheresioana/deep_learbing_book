{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b9be92",
   "metadata": {},
   "source": [
    "## Validating your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e1fa0",
   "metadata": {},
   "source": [
    "### Simple holdout validation\n",
    "This is the simplest evaluation protocol, and it suffers from one flaw: if little data is available, then your validation and test sets may contain too few samples to be statistically representative of the data at hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6bd3a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras import layers\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
    "    num_words=10000)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "import numpy as np \n",
    "def vectorize_sequences(sequences, dimension=10000): \n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j in sequence:\n",
    "            results[i, j] = 1.\n",
    "    return results\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "y_train = np.asarray(train_labels).astype(\"float32\")\n",
    "y_test = np.asarray(test_labels).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d51644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5282 - accuracy: 0.7883 - val_loss: 0.4460 - val_accuracy: 0.8165\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3385 - accuracy: 0.8897 - val_loss: 0.3205 - val_accuracy: 0.8845\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2536 - accuracy: 0.9157 - val_loss: 0.2903 - val_accuracy: 0.8852\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2071 - accuracy: 0.9297 - val_loss: 0.2805 - val_accuracy: 0.8869\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1719 - accuracy: 0.9436 - val_loss: 0.2731 - val_accuracy: 0.8887\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1465 - accuracy: 0.9525 - val_loss: 0.2820 - val_accuracy: 0.8861\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1290 - accuracy: 0.9597 - val_loss: 0.2889 - val_accuracy: 0.8852\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1113 - accuracy: 0.9657 - val_loss: 0.3030 - val_accuracy: 0.8816\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0978 - accuracy: 0.9708 - val_loss: 0.3121 - val_accuracy: 0.8842\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0827 - accuracy: 0.9773 - val_loss: 0.3544 - val_accuracy: 0.8768\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0704 - accuracy: 0.9823 - val_loss: 0.3548 - val_accuracy: 0.8743\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0625 - accuracy: 0.9839 - val_loss: 0.3626 - val_accuracy: 0.8795\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.0526 - accuracy: 0.9886 - val_loss: 0.4188 - val_accuracy: 0.8663\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0472 - accuracy: 0.9891 - val_loss: 0.3997 - val_accuracy: 0.8752\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0381 - accuracy: 0.9933 - val_loss: 0.4246 - val_accuracy: 0.8743\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0330 - accuracy: 0.9936 - val_loss: 0.4446 - val_accuracy: 0.8744\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 0.9948 - val_loss: 0.4682 - val_accuracy: 0.8731\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9954 - val_loss: 0.4871 - val_accuracy: 0.8708\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9984 - val_loss: 0.5117 - val_accuracy: 0.8704\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.0164 - accuracy: 0.9989 - val_loss: 0.5545 - val_accuracy: 0.8683\n"
     ]
    }
   ],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22470ca6",
   "metadata": {},
   "source": [
    "### K-fold validation\n",
    "With this approach, you split your data into K partitions of equal size. For each partition i, train a model on the remaining K - 1 partitions, and evaluate it on partition i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c379715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2bcd7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000), (25000, 1)\n",
      "[[0. 1. 1. ... 0. 0. 1.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 1.]\n",
      " [0. 1. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "y_train_two = np.reshape(y_train, (y_train.shape[0], 1))\n",
    "print(f\"{x_train.shape}, {y_train_two.shape}\")\n",
    "data = np.concatenate((x_train, y_train_two), axis=1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b040fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "8333\n",
      "Epoch 1/20\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.5550 - accuracy: 0.7788 - val_loss: 0.4302 - val_accuracy: 0.8625\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3525 - accuracy: 0.8880 - val_loss: 0.3272 - val_accuracy: 0.8798\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2630 - accuracy: 0.9098 - val_loss: 0.2876 - val_accuracy: 0.8908\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2137 - accuracy: 0.9267 - val_loss: 0.2746 - val_accuracy: 0.8937\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.1808 - accuracy: 0.9384 - val_loss: 0.2771 - val_accuracy: 0.8948\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.1545 - accuracy: 0.9491 - val_loss: 0.2816 - val_accuracy: 0.8896\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.1345 - accuracy: 0.9564 - val_loss: 0.2888 - val_accuracy: 0.8909\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.1184 - accuracy: 0.9612 - val_loss: 0.3323 - val_accuracy: 0.8794\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.1030 - accuracy: 0.9677 - val_loss: 0.3498 - val_accuracy: 0.8741\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0907 - accuracy: 0.9738 - val_loss: 0.3286 - val_accuracy: 0.8835\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0796 - accuracy: 0.9781 - val_loss: 0.3599 - val_accuracy: 0.8781\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0696 - accuracy: 0.9806 - val_loss: 0.3664 - val_accuracy: 0.8820\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0584 - accuracy: 0.9853 - val_loss: 0.4217 - val_accuracy: 0.8715\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0510 - accuracy: 0.9878 - val_loss: 0.4074 - val_accuracy: 0.8784\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0460 - accuracy: 0.9886 - val_loss: 0.4303 - val_accuracy: 0.8752\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0348 - accuracy: 0.9939 - val_loss: 0.4523 - val_accuracy: 0.8751\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0309 - accuracy: 0.9946 - val_loss: 0.5216 - val_accuracy: 0.8680\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0270 - accuracy: 0.9956 - val_loss: 0.5033 - val_accuracy: 0.8728\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9956 - val_loss: 0.5255 - val_accuracy: 0.8735\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9972 - val_loss: 0.5553 - val_accuracy: 0.8706\n",
      "[0.8624745011329651, 0.8797551989555359, 0.8907956480979919, 0.8936757445335388, 0.8947557806968689, 0.8895955681800842, 0.8909156322479248, 0.8793951869010925, 0.874114990234375, 0.8834753632545471, 0.878075122833252, 0.8820352554321289, 0.8714748620986938, 0.8784351348876953, 0.8751950263977051, 0.8750749826431274, 0.8679947257041931, 0.8727949261665344, 0.8735149502754211, 0.8706348538398743]\n",
      "8333\n",
      "16666\n",
      "Epoch 1/20\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.5302 - accuracy: 0.7801 - val_loss: 0.4172 - val_accuracy: 0.8462\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3269 - accuracy: 0.8961 - val_loss: 0.3216 - val_accuracy: 0.8757\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2419 - accuracy: 0.9192 - val_loss: 0.2803 - val_accuracy: 0.8889\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.1946 - accuracy: 0.9365 - val_loss: 0.3225 - val_accuracy: 0.8686\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.1652 - accuracy: 0.9453 - val_loss: 0.2779 - val_accuracy: 0.8892\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.1427 - accuracy: 0.9533 - val_loss: 0.2858 - val_accuracy: 0.8864\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.1231 - accuracy: 0.9617 - val_loss: 0.2994 - val_accuracy: 0.8830\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.1070 - accuracy: 0.9675 - val_loss: 0.3205 - val_accuracy: 0.8796\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0925 - accuracy: 0.9728 - val_loss: 0.3263 - val_accuracy: 0.8801\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0798 - accuracy: 0.9788 - val_loss: 0.3436 - val_accuracy: 0.8758\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0699 - accuracy: 0.9819 - val_loss: 0.3738 - val_accuracy: 0.8745\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0590 - accuracy: 0.9858 - val_loss: 0.3860 - val_accuracy: 0.8746\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0541 - accuracy: 0.9868 - val_loss: 0.4469 - val_accuracy: 0.8669\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0427 - accuracy: 0.9915 - val_loss: 0.4207 - val_accuracy: 0.8727\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0395 - accuracy: 0.9918 - val_loss: 0.4485 - val_accuracy: 0.8718\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0317 - accuracy: 0.9941 - val_loss: 0.4915 - val_accuracy: 0.8675\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9948 - val_loss: 0.4914 - val_accuracy: 0.8702\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9966 - val_loss: 0.5168 - val_accuracy: 0.8676\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9965 - val_loss: 0.5419 - val_accuracy: 0.8674\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0198 - accuracy: 0.9959 - val_loss: 0.5533 - val_accuracy: 0.8666\n",
      "[0.8461538553237915, 0.8756750226020813, 0.8888755440711975, 0.868594765663147, 0.8892355561256409, 0.886355459690094, 0.8829953074455261, 0.879635214805603, 0.8801152110099792, 0.8757950067520142, 0.8744750022888184, 0.8745949864387512, 0.866914689540863, 0.8726748824119568, 0.8718348741531372, 0.8675147294998169, 0.8701547980308533, 0.8676347136497498, 0.8673946857452393, 0.8665546774864197]\n",
      "16666\n",
      "24999\n",
      "Epoch 1/20\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.5189 - accuracy: 0.7814 - val_loss: 0.3766 - val_accuracy: 0.8727\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3033 - accuracy: 0.8994 - val_loss: 0.3102 - val_accuracy: 0.8834\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2237 - accuracy: 0.9239 - val_loss: 0.3108 - val_accuracy: 0.8765\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.1826 - accuracy: 0.9380 - val_loss: 0.2840 - val_accuracy: 0.8890\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.1509 - accuracy: 0.9506 - val_loss: 0.3242 - val_accuracy: 0.8758\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.1309 - accuracy: 0.9570 - val_loss: 0.3102 - val_accuracy: 0.8842\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.1127 - accuracy: 0.9652 - val_loss: 0.3341 - val_accuracy: 0.8759\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0962 - accuracy: 0.9699 - val_loss: 0.3522 - val_accuracy: 0.8787\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0790 - accuracy: 0.9782 - val_loss: 0.3582 - val_accuracy: 0.8787\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0720 - accuracy: 0.9791 - val_loss: 0.3750 - val_accuracy: 0.8802\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0589 - accuracy: 0.9844 - val_loss: 0.3995 - val_accuracy: 0.8804\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0529 - accuracy: 0.9858 - val_loss: 0.4215 - val_accuracy: 0.8774\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9899 - val_loss: 0.4523 - val_accuracy: 0.8721\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0343 - accuracy: 0.9930 - val_loss: 0.4705 - val_accuracy: 0.8723\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0304 - accuracy: 0.9939 - val_loss: 0.5070 - val_accuracy: 0.8690\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0275 - accuracy: 0.9948 - val_loss: 0.5164 - val_accuracy: 0.8741\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9975 - val_loss: 0.5489 - val_accuracy: 0.8706\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9969 - val_loss: 0.5706 - val_accuracy: 0.8716\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0147 - accuracy: 0.9978 - val_loss: 0.6318 - val_accuracy: 0.8632\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.6176 - val_accuracy: 0.8700\n",
      "[0.8726748824119568, 0.8833553194999695, 0.8765150308609009, 0.8889955878257751, 0.8757950067520142, 0.8841953873634338, 0.8759150505065918, 0.8786751627922058, 0.8786751627922058, 0.8802351951599121, 0.8803552389144897, 0.8773550987243652, 0.8720749020576477, 0.8723148703575134, 0.8689547777175903, 0.874114990234375, 0.8706348538398743, 0.8715948462486267, 0.8631945252418518, 0.8700348138809204]\n",
      "[[0.8624745011329651, 0.8797551989555359, 0.8907956480979919, 0.8936757445335388, 0.8947557806968689, 0.8895955681800842, 0.8909156322479248, 0.8793951869010925, 0.874114990234375, 0.8834753632545471, 0.878075122833252, 0.8820352554321289, 0.8714748620986938, 0.8784351348876953, 0.8751950263977051, 0.8750749826431274, 0.8679947257041931, 0.8727949261665344, 0.8735149502754211, 0.8706348538398743], [0.8461538553237915, 0.8756750226020813, 0.8888755440711975, 0.868594765663147, 0.8892355561256409, 0.886355459690094, 0.8829953074455261, 0.879635214805603, 0.8801152110099792, 0.8757950067520142, 0.8744750022888184, 0.8745949864387512, 0.866914689540863, 0.8726748824119568, 0.8718348741531372, 0.8675147294998169, 0.8701547980308533, 0.8676347136497498, 0.8673946857452393, 0.8665546774864197], [0.8726748824119568, 0.8833553194999695, 0.8765150308609009, 0.8889955878257751, 0.8757950067520142, 0.8841953873634338, 0.8759150505065918, 0.8786751627922058, 0.8786751627922058, 0.8802351951599121, 0.8803552389144897, 0.8773550987243652, 0.8720749020576477, 0.8723148703575134, 0.8689547777175903, 0.874114990234375, 0.8706348538398743, 0.8715948462486267, 0.8631945252418518, 0.8700348138809204]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 3 \n",
    "num_validation_samples = len(data) // k\n",
    "np.random.shuffle(data)\n",
    "all_acc_histories = [] \n",
    "validation_scores = [] \n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_samples * fold:\n",
    "                           num_validation_samples * (fold + 1)]\n",
    "    training_data = np.concatenate((\n",
    "        data[:num_validation_samples * fold],\n",
    "        data[num_validation_samples * (fold + 1):]))\n",
    "    model = get_model()\n",
    "    history = model.fit(training_data[:, :-1],\n",
    "                        training_data[:, -1],\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(validation_data[:, :-1],validation_data[:, -1]))\n",
    "    acc_history = history.history[\"val_accuracy\"]\n",
    "    all_acc_histories.append(acc_history)\n",
    "    print(acc_history)\n",
    "\n",
    "print(all_acc_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48638527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8762170523405075\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(all_acc_histories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e4d61",
   "metadata": {},
   "source": [
    "### Iterated K-fold validation with shuffling\n",
    "This one is for situations in which you have relatively little data available and you need to evaluate your model as precisely as possible. I’ve found it to be extremely helpful in Kaggle competitions. It consists of applying K-fold validation multiple times, shuffling the data every time before splitting it K ways. The final score is the average of the scores obtained at each run of K-fold validation. Note that you end up training and evaluating P * K models (where P is the number of iterations you use), which can be very expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60945e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41af91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2df0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (exercises)",
   "language": "python",
   "name": "pycharm-c686091e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
